# RAG System - Weekend Hackathon to Production

A comprehensive Retrieval-Augmented Generation (RAG) system that can be built in a weekend and extended into production.

## ğŸš€ Quick Start (Weekend Hackathon)

```bash
# 1. Setup environment
python -m venv rag_env
source rag_env/bin/activate  # On Windows: rag_env\Scripts\activate
pip install -r requirements.txt

# 2. Set environment variables
cp .env.example .env
# Edit .env with your API keys

# 3. Initialize database
python scripts/init_db.py

# 4. Start the system
python main.py

# 5. Open http://localhost:8000/docs for API docs
```

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Ingestion     â”‚    â”‚  Preprocessing   â”‚    â”‚   Chunking      â”‚
â”‚   (PDF/HTML/    â”‚â”€â”€â”€â–¶â”‚  & Parsing      â”‚â”€â”€â”€â–¶â”‚  & Embeddings   â”‚
â”‚   Markdown)     â”‚    â”‚                  â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Versioning    â”‚    â”‚  Vector Store    â”‚    â”‚   Retrieval     â”‚
â”‚   & Updates     â”‚    â”‚  + Metadata DB   â”‚    â”‚   + Reranking   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Evaluation    â”‚    â”‚  LLM Generation  â”‚    â”‚   Attribution   â”‚
â”‚   & Monitoring  â”‚â—€â”€â”€â”€â”‚  + Grounding     â”‚â—€â”€â”€â”€â”‚   & Citations   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
RAG_hac/
â”œâ”€â”€ app/                    # Main application
â”‚   â”œâ”€â”€ api/              # FastAPI endpoints
â”‚   â”œâ”€â”€ core/             # Configuration & utilities
â”‚   â”œâ”€â”€ models/           # Data models & schemas
â”‚   â”œâ”€â”€ services/         # Business logic
â”‚   â””â”€â”€ utils/            # Helper functions
â”œâ”€â”€ data/                  # Data storage
â”‚   â”œâ”€â”€ documents/        # Original documents
â”‚   â”œâ”€â”€ chunks/           # Processed chunks
â”‚   â””â”€â”€ embeddings/       # Vector embeddings
â”œâ”€â”€ scripts/               # Setup & utility scripts
â”œâ”€â”€ tests/                 # Test suite
â”œâ”€â”€ config/                # Configuration files
â””â”€â”€ docs/                  # Documentation
```

## ğŸ”§ Core Features

### 1. Multi-Format Document Ingestion
- **PDF**: Text extraction + OCR with Tesseract
- **HTML**: DOM parsing with BeautifulSoup
- **Markdown**: Front-matter parsing
- **Code**: Syntax-aware chunking
- **Images**: OCR processing

### 2. Intelligent Chunking
- Semantic splitting by headings/sections
- Sliding window with overlap (200-600 tokens)
- Code block preservation
- Hierarchical chunking

### 3. Vector Search & Retrieval
- FAISS for local development
- Hybrid search (BM25 + vector similarity)
- Metadata filtering
- Reranking with cross-encoders

### 4. Grounded Generation
- LLM integration (OpenAI/Anthropic)
- Source citation & attribution
- Confidence scoring
- Hallucination prevention

### 5. Versioning & Updates
- Incremental document updates
- Change detection via checksums
- Backward compatibility
- Release management

## ğŸ¯ Weekend MVP Roadmap

### Day 1: Core Infrastructure
- [x] Project setup & dependencies
- [ ] Basic document ingestion (PDF/Text)
- [ ] Simple chunking strategy
- [ ] FAISS vector store setup
- [ ] Basic retrieval API

### Day 2: Intelligence & UI
- [ ] LLM integration & grounding
- [ ] Web interface for queries
- [ ] Document upload & management
- [ ] Basic evaluation metrics

### Day 3: Polish & Extensions
- [ ] Advanced chunking strategies
- [ ] Hybrid search implementation
- [ ] Attribution & citations
- [ ] Performance optimization

## ğŸš€ Production Extensions

- **Scalability**: Milvus/Pinecone vector DBs
- **Security**: Multi-tenant isolation, PII detection
- **Monitoring**: Prometheus + Grafana dashboards
- **CI/CD**: Automated testing & deployment
- **Compliance**: Audit logs, data retention policies

## ğŸ“Š Evaluation Metrics

- **Retrieval**: Recall@k, Precision@k, MRR, nDCG
- **Generation**: Factuality rate, hallucination detection
- **User Experience**: Response time, user satisfaction

## ğŸ” Environment Variables

```bash
# LLM APIs
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key

# Vector DB (optional)
PINECONE_API_KEY=your_pinecone_key
PINECONE_ENVIRONMENT=your_environment

# Database
DATABASE_URL=sqlite:///./rag_system.db
# or DATABASE_URL=postgresql://user:pass@localhost/rag_db

# Security
SECRET_KEY=your_secret_key
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=app tests/

# Run specific test
pytest tests/test_retrieval.py -v
```

## ğŸ“ˆ Performance Benchmarks

- **Document Processing**: ~100 docs/minute
- **Query Response**: <500ms average
- **Vector Search**: <100ms for 100k chunks
- **Memory Usage**: ~2GB for 10k documents

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Ensure all tests pass
5. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details
